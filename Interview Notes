‚úÖ Interview Answer ‚Äì Kubernetes Components (Control Plane & Worker Node)
üß† 1. Control Plane Components

The control plane is the brain of the Kubernetes cluster. It makes global decisions about the cluster, like scheduling, scaling, and healing.
üîπ a. API Server (kube-apiserver)

    The front door of the Kubernetes cluster.

    It exposes the Kubernetes API and is the communication hub between all components (CLI, UI, internal components).

    All kubectl commands interact with the API server.

    üß† Analogy: Think of it as the reception desk of a company. Every request goes through it ‚Äî it authenticates, validates, and routes to the right department.

üîπ b. Scheduler (kube-scheduler)

    Decides which node a new pod should run on.

    It considers resource requirements, taints/tolerations, node affinity, and constraints.

    üß† Analogy: Like a job placement officer assigning tasks to employees based on skills and workload.

üîπ c. Controller Manager (kube-controller-manager)

    Runs various controllers that maintain cluster state, like:

        Node controller (monitors node health)

        ReplicaSet controller (ensures correct pod count)

        Endpoints controller, Job controller, etc.

    These controllers continuously reconcile the desired state with the actual state.

    üß† Analogy: Think of it as a team of supervisors making sure everything stays on track.

üîπ d. etcd (Key-Value Store)

    The backend database for Kubernetes.

    Stores all cluster data including config, secrets, and state.

    It's a distributed, consistent, and highly available key-value store.

    üß† Analogy: Like a filing cabinet or brain memory where all decisions and records are stored.

üîπ e. (Optional) Cloud Controller Manager

    Integrates with cloud providers (AWS, GCP, Azure).

    Handles cloud-specific resources like load balancers, nodes, storage volumes.

    üß† Analogy: A cloud integration officer that talks to external service providers.

üñ•Ô∏è 2. Worker Node Components

The worker nodes are where the actual applications (containers) run.
üîπ a. Kubelet

    Agent running on each node.

    Receives PodSpecs from the API server and ensures the containers are running as expected.

    Reports health/status back to the control plane.

    üß† Analogy: Like a factory worker executing tasks assigned by management.

üîπ b. Container Runtime

    The software responsible for running containers (e.g., containerd, CRI-O, Docker).

    Kubelet interacts with it to start/stop containers.

    üß† Analogy: Like the machinery in the factory that actually does the work.

üîπ c. kube-proxy

    Manages network rules on nodes.

    Enables service-to-pod communication using cluster IPs.

    Handles routing, NAT, and forwarding.

    üß† Analogy: Acts as a network traffic officer, making sure data reaches the right pods.





###############################################

üì¶ Namespaced Resources

These resources exist within a specific namespace, providing a way to partition and organize resources within a single cluster. Each namespaced resource is isolated from those in other namespaces, allowing for multi-tenancy and resource management.‚Äã
Percona+2kubecost.com+2Medium+2

Examples include:

    Pods

    Services

    Deployments

    ConfigMaps

    Secrets

    Ingresses‚Äã
    plural.sh+8Kubernetes+8Reddit+8

When creating or managing these resources, you specify the namespace they belong to. If no namespace is specified, they default to the default namespace.‚Äã

Use Cases:

    Separating environments (e.g., development, staging, production)

    Isolating resources for different teams or projects

    Applying resource quotas and access controls per namespace‚Äã
    Aqua+4LoftLabs - Virtual Kubernetes Clusters+4kubecost.com+4
    ARMO+5kubecost.com+5Medium+5

üåê Cluster-Scoped Resources

These resources are not confined to a namespace and are accessible across the entire cluster. They are used for configurations and components that are global to the cluster's operation.‚Äã

Examples include:

    Nodes

    PersistentVolumes

    Namespaces themselves

    ClusterRoles and ClusterRoleBindings

    CustomResourceDefinitions (CRDs)‚Äã
    plural.sh+1Reddit+1
    Medium
    Aqua+1Medium+1
    Stack Overflow+5Reddit+5LoftLabs - Virtual Kubernetes Clusters+5

Use Cases:

    Defining cluster-wide policies and roles

    Managing physical or virtual nodes

    Setting up storage volumes accessible by multiple namespaces‚Äã
    Percona

üß† Analogy

Think of a Kubernetes cluster as a company building:‚Äã

    Cluster-Scoped Resources: These are like the building's infrastructure‚Äîelevators, security systems, or the main power supply‚Äîthat serve the entire building.‚Äã

    Namespaced Resources: These are like individual offices or departments within the building, each with its own equipment, staff, and access controls.‚Äã

This structure allows multiple teams to operate independently within the same cluster, ensuring organization, security, and efficient resource utilization


####################################################################################
üîπ DevOps focuses on software development lifecycles ‚Äî ensuring that code moves quickly, reliably, and automatically from development to production.
It emphasizes CI/CD pipelines, infrastructure as code, monitoring, automation, and collaboration between developers and operations.

üîπ MLOps is an extension of DevOps principles to the machine learning lifecycle.
It manages not just code, but also models, data, and experiments ‚Äî automating model training, validation, deployment, and monitoring.
It deals with additional challenges like versioning datasets, model drift, and retraining pipelines ‚Äî which aren't typical concerns in standard DevOps.

"DevOps is about deploying applications; MLOps is about deploying models ‚Äî and models keep learning and changing with data, so the operational challenges are bigger."
"Think of DevOps as managing a well-defined assembly line producing identical products. MLOps, however, is like managing a research lab where experiments continuously evolve, and outcomes are uncertain, requiring constant oversight and adaptation."‚Äã

###########################################################################################
n Kubernetes, pods communicate with each other using networking primitives provided by the cluster's network model. Here‚Äôs a clear breakdown of how that works:
üîó 1. Pod-to-Pod Communication (within a Node or across Nodes)

    Flat, routable network: Every pod gets its own unique IP address. This means:

        Pods can communicate directly via IP (without NAT).

        No need to expose pods via services to communicate internally.

    CNI Plugin: Kubernetes uses a Container Network Interface (CNI) plugin (like Calico, Flannel, Cilium) to set up networking across nodes so that:

        Pod A on Node 1 can reach Pod B on Node 2 via their IPs.

        The plugin configures routes, bridges, and IP allocation.

üì¶ 2. Pod Communication via Services

    Pods are ephemeral. To communicate reliably:

        Kubernetes Service gives a stable DNS name and virtual IP.

        Backed by a group of pods selected via labels.

        Example:

            service-a.default.svc.cluster.local points to a set of pods.

    Types of services:

        ClusterIP (default): for internal communication.

        NodePort / LoadBalancer: for external access.

        Headless service: useful when you want to discover individual pod IPs (like in StatefulSets).

‚öôÔ∏è 3. DNS Resolution

    Kubernetes runs a CoreDNS service in the cluster.

    It enables pods to resolve service names like:

    http://my-service.my-namespace.svc.cluster.local

üîê 4. Network Policies (Optional)

    By default, all pods can talk to all other pods.

    You can restrict traffic using NetworkPolicies:

        Define what ingress/egress is allowed based on pod labels, namespaces, and ports.

        Enforced by network plugins that support them (like Calico).

Summary
Method	Use Case	Scope
Direct IP (Pod-to-Pod)	Low-level communication/testing	Cluster-wide
ClusterIP Service	Stable, reliable communication	Internal only
Headless Service + DNS	Stateful sets, service discovery	Internal only
Network Policy	Restrict or allow traffic	Security Layer


##############################################################################################
# Linux File System Interview Questions & Answers

## Beginner Level

### 1. What is a file system in Linux?

A file system defines how data is stored and retrieved on a disk. It organizes files hierarchically and manages metadata like permissions, timestamps, and ownership.

### 2. What are common Linux file systems?

* **ext2, ext3, ext4** ‚Äì Traditional Linux file systems
* **xfs** ‚Äì High-performance journaling file system
* **btrfs** ‚Äì Modern, supports snapshots and RAID
* **vfat** ‚Äì Windows-compatible
* **ntfs** ‚Äì Used to access Windows drives

### 3. What is the root directory (`/`) in Linux?

The top-level directory. All files and directories branch from it.

### 4. What is the difference between absolute and relative path?

* **Absolute path**: Starts from root (`/`), e.g. `/etc/nginx/nginx.conf`
* **Relative path**: From current directory, e.g. `../logs/app.log`

### 5. What are inode and block in Linux?

* **inode**: Metadata about a file (permissions, owner, etc.)
* **block**: Stores actual file data

### 6. What command shows disk usage of directories?

* `du -sh *` ‚Äî Disk usage of current directory items
* `df -h` ‚Äî Free and used disk space on mounted filesystems

### 7. What is the purpose of `/etc/fstab`?

Defines static information about filesystems and how they should mount at boot.

## Intermediate Level

### 8. How do you mount and unmount a file system manually?

```bash
mount /dev/sdb1 /mnt/data
umount /mnt/data
```

### 9. How do you check file system type of a partition?

```bash
lsblk -f
blkid /dev/sdb1
file -s /dev/sdb1
```

### 10. How do you create a file system on a new disk?

```bash
mkfs.ext4 /dev/sdb1
mkfs.xfs /dev/sdc1
```

### 11. What are hard links and soft links (symlinks)?

* **Hard link**: Same inode; deleting one doesn‚Äôt affect the other
* **Soft link**: Points to file path; breaks if original is deleted

```bash
ln file1 file2        # Hard link
ln -s file1 symlink   # Soft link
```

### 12. What happens when a file is deleted but is still open by a process?

It disappears from directory view, but stays on disk until the process releases it.

### 13. How to check open files and filesystem usage?

```bash
lsof
 df -hT
 du -sh
```

### 14. How to check and repair a file system?

```bash
fsck /dev/sda1
```

(Use when unmounted or in single-user mode)

## Advanced Level

### 15. What is journaling in file systems like ext3/ext4?

Records metadata changes in a journal before applying, ensuring integrity and quicker recovery.

### 16. How do LVM and the file system interact?

LVM abstracts physical storage. Resize with LVM commands and tools like `resize2fs` or `xfs_growfs`.

### 17. How do you grow an ext4 file system without reboot?

```bash
lvextend -L +5G /dev/vg0/lv_data
resize2fs /dev/vg0/lv_data
```

### 18. What is the difference between ext4 and xfs?

* **ext4**: Default in most distros, good for small/mid workloads
* **xfs**: Better performance for large files, faster growth

### 19. How can you bind mount a directory?

```bash
mount --bind /data/shared /var/www/html/shared
```

### 20. What is tmpfs and when is it used?

`tmpfs` stores data in RAM. Used in `/tmp`, `/run`, etc. for fast temporary storage.

```bash
mount -t tmpfs -o size=512M tmpfs /mnt/tmp
```

### 21. What happens if root (`/`) file system is full?

System may crash or hang. Separate `/var`, `/tmp`, etc. recommended to prevent this.

### 22. What are ACLs and how do they differ from normal permissions?

ACLs allow more granular permission settings for multiple users/groups.

```bash
setfacl -m u:john:rwx file.txt
getfacl file.txt
```#####################################################################################
**Kubernetes In-Place Pod Vertical Scaling**

Traditionally, modifying the resource allocation for a Kubernetes pod required a restart, potentially disrupting applications and causing downtime. In-place scaling changes this by enabling real-time CPU and memory adjustments while the pod continues running. This is particularly useful for workloads with a very low tolerance for pod evictions.

What‚Äôs behind the feature gate?

The new resizePolicy spec element allows you to specify how a pod reacts to a patch command that changes its resource requests, enabling changing resource requests without rescheduling the pod.

The result of the change attempt is communicated as part of the pods‚Äô status in a field called  resize (for more information on the new fields, check out the Kubernetes API documentation.)

Additionally, this feature introduces the restartPolicy in the spec element for containers, allowing fine-grained control over resizing behavior and allowing the developer to choose if CPU change or Memory change should lead to rescheduling the pod.

Key Features

Dynamic Scaling: Modify CPU and memory allocations while pods run.
No Restarts: Avoid downtime caused by pod restarts.
Granular Control: Enable precise resource tuning for better efficiency.
How It Works
The InPlacePodVerticalScaling feature integrates seamlessly into Kubernetes to provide a more dynamic approach to resource allocation. Here‚Äôs a detailed breakdown of how it operates:

Feature Gate Activation: Activating the InPlacePodVerticalScaling feature gate in your cluster configuration is required to enable this functionality. This allows the kubelet on each node to detect and process resource updates dynamically.
Dynamic Resource Updates via Kube API: With the feature enabled, the kubelet directly applies resource changes to running pods without requiring restarts. Supported container runtimes (e.g., containerd v1.6.9 or later) ensure these updates are applied efficiently. If constraints like insufficient free memory or CPU prevent the changes, the pod follows the regular flow: it is recreated and rescheduled.
Pod Spec Adjustments: The resizePolicy field dictates how CPU and memory adjustments are handled. For instance, you can set NotRequired for live updates without restarts or RestartContainer to force a restart when a specific resource is modified.

####################################################################################################
By default, SonarQube uses port 9000 for incoming HTTP connections. 
This is specified in the SonarQube Server configuration file (<sonarqubeHome>/conf/sonar.properties) for a ZIP installation or as an environment variable (SONAR_WEB_PORT) for a Docker installation
###############################################################
Nexus Software Tool- Port 8081

Nexus is a powerful repository manager designed to manage and organize artifacts throughout the software development lifecycle. 
It serves as a centralized repository for storing, retrieving, and managing software artifacts such as JAR files, Docker images, npm packages, and other components

Key Features and Benefits

Centralized Artifact Management
Nexus provides a central location for storing various types of software artifacts, ensuring consistency across development, 
testing, and production environments. It supports version control and metadata management, allowing teams to easily access the components they need for their projects

Enhanced Collaboration
Nexus fosters collaboration among development, operations, and quality assurance teams by providing a shared platform for storing and managing artifacts. 
It enforces access control policies, ensuring that only authorized users can access or modify the artifacts

Automated Build Processes
Nexus integrates with build tools like Maven and Gradle to automate the retrieval of dependencies from the Nexus repository. 
It also integrates with CI/CD tools like Jenkins and GitLab, enabling automated builds and promoting artifacts across different stages of deployment pipelines


Scalability and Versatility
Nexus supports a wide range of programming languages and package formats, making it suitable for diverse deployment environments. 
It can scale up to manage large volumes of artifacts, dependencies, and users without compromising performance or reliability


Improved Stability and Reliability
Nexus ensures that dependencies are sourced from trusted and reliable locations, reducing the risk of build failures. 
It provides mechanisms for disaster recovery and deployment in clustered configurations, minimizing downtime and ensuring continuous access to artifacts

#############################################################################################
In Kubernetes, Quality of Service (QoS) for a Pod determines the priority and guarantees that 
the pod receives for CPU and memory resources, especially when the node is under resource pressure.

There are three QoS classes:

1. Guaranteed
All containers in the pod have CPU and memory requests equal to limits.
Best QoS ‚Äî the pod is the last to be evicted if the node is under memory pressure.

2. Burstable
At least one container has resource requests, but not all limits are equal to requests.
Mid-tier QoS ‚Äî gets evicted before Guaranteed but after BestEffort.

3. BestEffort
No requests or limits are specified for any container.
Lowest QoS ‚Äî first to be evicted under resource pressure.

Why QoS Matters
During resource contention, Kubernetes evicts BestEffort first, then Burstable, and Guaranteed pods are the most protected.
Helps ensure critical workloads have consistent performance.

##############################################################
Read about ingress annotations, clusterd and namespaced resources
Distroless images in Docker are minimal container images that do not contain a full Linux distribution, 
such as apt, bash, or yum. They include only the essential application dependencies and runtime libraries required to run the application


##############################################################    
"A Pod Disruption Budget (PDB) is a Kubernetes feature that lets you define how many pods from a set can be unavailable during voluntary disruptions 
like node upgrades or scaling events. It helps ensure high availability of your application by preventing too many pods from going down at the same time."
üîç Example to Mention:
‚ÄúFor example, if I have 5 replicas of a service, I can set a PDB that allows only 1 pod to be unavailable at a time. 
This way, Kubernetes won‚Äôt evict more than one pod during maintenance or updates, ensuring the service stays up.‚Äù


##############################################################
